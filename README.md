![](https://miro.medium.com/v2/resize:fit:1400/1*a6GbKZOzFyEpszG1JVnddw.png)

About this project
==================

In recent years, chatbots have become increasingly popular for providing personalized recommendations and advice in various fields, including skincare. Skincare chatbots can help users identify their skin concerns, recommend products, and provide tips and tricks for maintaining healthy skin.

For this project, I've built a retrieval-based skincare chatbot that will guide users about their skincare routines based on their needs. It would also guide users about CeraVe products available, new products, best sellers, and ingredients contained in a product. You can also trust this chatbot to give you skincare tips for that glass skin.

![](https://miro.medium.com/v2/resize:fit:568/1*OtbnlCB2qXSkqgTlJcg9HQ.png)

[source](https://dzone.com/articles/significance-of-chatbot)

Dataset used
============

The dataset is a JSON file that includes data collected from the CeraVe website. The dataset consists of 54 intents, each with its own patterns and responses, and is structured in the following format:

{\
"tag": "skincare_tips",\
"patterns": [\
"share skincare tips", ...\
  ],\
"responses": [\
"Stay Hydrated ğŸ’†ğŸ» ", ...\
  ],\
"context": [\
""\
  ]\
}

Implementation
==============

1\. Import necessary packages
-----------------------------

First of all, I've installed and imported all the packages that will be required for the project. I've also loaded the TensorBoard extension for Jupyter notebooks to visualize the training progress of their TensorFlow models, compare the performance of different models, and analyze the distributions and histograms of model parameters.

2\. Load and preprocess the data file
-------------------------------------

In this step, I loaded the dataset and parsed the JSON file, and then preprocessed the data using the process of tokenization and label encoder. Tokenization is the process of breaking a string of text into smaller pieces called tokens and label encoding is used for encoding categorical variables as numerical values.

3\. Build the model
-------------------

In this step, I defined and compiled a linear stack of layers for a deep-learning model using the Keras library. The first layer is anÂ `Input`Â layer that specifies the shape of the input data that the model will receive. The next layer is anÂ `Embedding`Â layer that converts each word in the input data into a fixed-length vector of a defined size. The model also includes aÂ `Dropout`Â layer, which randomly sets input units to 0 with a rate of 0.3 to reduce overfitting. The model then has aÂ `SimpleRNN`Â layer, which is a fully-connected RNN where the output is fed back to the input. This is followed by aÂ `BatchNormalization`Â layer, which normalizes the activations of the previous layer. The model also has aÂ `Dense`Â layer with aÂ `relu`Â activation function and anÂ `L2`Â regularizer, which applies penalties on the layer parameters to prevent overfitting. The final layer is aÂ `Dense`Â layer with aÂ `softmax`Â activation function, which normalizes the output of the network to a probability distribution over the predicted output classes. The model is then compiled by specifying the loss function asÂ `sparse_categorical_crossentropy`Â and the optimizer asÂ `adam`, and specifying the metric to be tracked asÂ `accuracy`.

4\. Testing the model
---------------------

Next, I set up two callbacks for training a deep learning model using the Keras library: anÂ `EarlyStopping`Â callback and aÂ `TensorBoard`Â callback. TheÂ `EarlyStopping`Â callback is used to stop the training when there is no improvement in the loss for a specified number of consecutive epochs. In this case, the callback is set to stop the training when there is no improvement in the loss for 400 epochs. TheÂ `TensorBoard`Â callback is used to log the training progress for visualization in TensorBoard. The model is then trained for 2000 epochs with a batch size of 64, and the two callbacks are passed to theÂ `fit`Â method as arguments. TheÂ `fit`Â method trains the model on the specified features and labels and returns a history object containing the training loss and metrics for each epoch.

Results:
--------

![](https://miro.medium.com/v2/resize:fit:1400/1*UIJl4q0x3EqKYUsWWz4gbw.png)

Accuracy curve:
---------------

![](https://miro.medium.com/v2/resize:fit:1400/1*RaXBgGm6TbuVk-Nh2ScgCw.png)

Loss curve:
-----------

![](https://miro.medium.com/v2/resize:fit:1400/1*yLCj5Ah67tIEM6zJtOYAvw.png)

5\. Generating responses
------------------------

In this step, a function to generate responses is defined that takes a user input query as input and returns a list of tuples containing the user's query and the bot's response. The function first processes the user input by lowercasing the letters and removing punctuation. The processed input is then tokenized using theÂ `tokenizer`Â object and transformed into numerical data using theÂ `texts_to_sequences`Â method. The numerical data is then padded to a fixed length using theÂ `pad_sequences`Â function. The padded numerical data is then used as input to the model, which predicts the output using theÂ `predict`Â method. The output is transformed back into the original data from numerical values using theÂ `inverse_transform`Â method of theÂ `labelEncoder`Â object. The bot's response is chosen randomly from a list of possible responses stored in theÂ `responses`Â dictionary. The user's query and the bot's response are then appended to theÂ `history`Â list and the list is returned by the function.

6\. Create the user interface
-----------------------------

Finally, for the UI I used the Gradio library for a better user experience and have also used custom CSS to further enhance the UI which can be found in the code repo.

7\. Run the chatbot
-------------------

Now that we have implemented our chatbot its now time to interact with it and test its performance. I've attached a couple of screenshots of our chatbot interaction with real users' queries.

![](https://miro.medium.com/v2/resize:fit:1560/1*mB7m8W3qoYSiqF7c6t-GYA.png)

![](https://miro.medium.com/v2/resize:fit:1584/1*5vkyLMX3gddA-xWg_7hPbg.png)

![](https://miro.medium.com/v2/resize:fit:1592/1*nkovfdlYwUv4JDjNR9eo6g.png)

![](https://miro.medium.com/v2/resize:fit:1482/1*OFiVJg7GvsZwAFns5-FJPg.png)

![](https://miro.medium.com/v2/resize:fit:1500/1*qMk0lG6qGI1fCSaO1PyoJA.png)

![](https://miro.medium.com/v2/resize:fit:1512/1*p0rRFFsDJ0Ba8AeqFkQF0Q.png)

Demo Link: 
----------
https://youtu.be/dFPCwRgH35c?si=Ayxgkjyp1gXicwQ5
